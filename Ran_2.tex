\documentclass[11pt,a4paper]{report}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts,amsmath,amssymb,suetterl}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[utf8]{inputenc}

\usepackage{fontawesome}
\DeclareUnicodeCharacter{2212}{-}
\usepackage{mathrsfs}

\usepackage[nodisplayskipstretch]{setspace}


\setstretch{1.5}


\fancyfoot[C]{\thepage}

\renewcommand{\footrulewidth}{0pt}
\parindent 0ex
\setlength{\parskip}{1em}

\newenvironment{psmallmatrix}
  {\left(\begin{smallmatrix}}
  {\end{smallmatrix}\right)}

\begin{document}
    \textbf{MTH6141 Random Processes}\\
    \textbf{Solutions to Exercise Sheet 2}

    \begin{enumerate}
        \item 
        \begin{enumerate}
            \item Using basic linear algebra we get that the eigenvalues of $P$ are $1$ and $1/2$ with eigenvectors $\begin{psmallmatrix}1 \\ 1\end{psmallmatrix}$ and $\begin{psmallmatrix}1 \\ -1/2\end{psmallmatrix}$. It follows that:
            %
            \[P = \begin{pmatrix}
                1 & 1 \\
                1 & -\frac{1}{2}
            \end{pmatrix}
            %
            \begin{pmatrix}
                1 & 0 \\
                0 & \frac{1}{2}
            \end{pmatrix}
            %
            \begin{pmatrix}
                \frac{1}{3} & \frac{2}{3} \\
                \frac{2}{3} & -\frac{2}{3}
            \end{pmatrix}\]
            So
            \[P^5 = \begin{pmatrix}
                1 & 1 \\
                1 & -\frac{1}{2}
            \end{pmatrix}
            %
            \begin{pmatrix}
                1 & 0 \\
                0 & \frac{1}{32}
            \end{pmatrix}
            %
            \begin{pmatrix}
                \frac{1}{3} & \frac{2}{3} \\
                \frac{2}{3} & -\frac{2}{3}
            \end{pmatrix}
            =
            \begin{pmatrix}
                \frac{1}{3}+\frac{1}{48} & \frac{2}{3}-\frac{1}{48} \\
                \frac{1}{3}-\frac{1}{96} & \frac{2}{3}+\frac{1}{96}
            \end{pmatrix}\]
            %
            \item The matrix $P^5$ gives the $5$-step transition probabilities so we can read off the matrix that $$\mathbb{P}(X_5=1\, |\, X_0=1)=p_{11}^{(5)}=\frac{1}{3}+\frac{1}{48}=\frac{17}{48}$$ $$\mathbb{P}(X_5 = 1\, | \, X_0 = 2) = p_{21}^{(5)} = \frac{1}{3}-\frac{1}{96}=\frac{31}{96}$$
            \item Similarly to part $(a)$ we have that
            \[P^{20} = \begin{pmatrix}
                1 & 1\\
                1 & -\frac{1}{2}
            \end{pmatrix}
            %
            \begin{pmatrix}
                1 & 0\\
                0 & 2^{-20}
            \end{pmatrix}
            %
            \begin{pmatrix}
                \frac{1}{3} & \frac{2}{3}\\
                \frac{2}{3} & -\frac{2}{3}
            \end{pmatrix}
            %
            =
            \begin{pmatrix}
                \frac{1}{3}+\frac{2}{3\times 2^{20}} & \frac{2}{3} - \frac{2}{3\times 2^{20}}\\
                \frac{1}{3}-\frac{1}{3\times 2^{30}} & \frac{2}{3}+\frac{1}{3\times 2^{20}}
            \end{pmatrix}
                \]
            and so $$\mathbb{P}(X_{20}=1\, | \, X_0 = 1) = \frac{1}{3}(1+2^{-19})$$ $$\mathbb{P}(X_{20}=1\, | \, X_0 = 2) = \frac{1}{3}(1-2^{-20}).$$
            \item The probabilities in part $(b)$ are fairly close and those in part $(c)$ are very close. This is saying that the process forgets its starting state in the sense that $\mathbb{P}(X_{20}=1\, | \, X_0 = i)$ does not depend very much on $i$.If you were to calculate $\mathbb{P}(X_n=1\, | \, X_0 = 1)$ and $\mathbb{P}(X_n = 1\, | \, X_0 = 2)$ for even larger $n$ they would be even closer and in the limit as $n\to \infty$ they are equal.
        \end{enumerate}
        \item 
        \begin{enumerate}
            \item States $1$ and $4$ are absorbing (because $p_{11}=p_{44}=1$).
            \item To do this we use first step analysis. Let $T$ be the time of absorption. Define $$a_i=\mathbb{P}(X_T=1\,|\,X_0=i).$$The question asks us to find $a_2$.\par
            Plainly $a_1=1$ and $a_4 = 0$. Now using first step analysis (that is conditioning on the first step the chain takes) we obtain the equations: $$a_2=\frac{1}{4}+\frac{1}{4}a_2+\frac{1}{4}a_3$$ $$a_3=\frac{1}{6}+\frac{1}{6}a_2+\frac{1}{6}a_3.$$ Solving these gives $\mathbb{P}(X_T=1)=a_2=\frac{3}{7}$ (and $a_3=\frac{2}{7}$).
        \end{enumerate}
        \item
        \begin{enumerate}
            \item The most direct way to model the process is to construct a Markov chain whose states remember the last two throws of the die. This requires $36$ states. In addition, we introduce a starting state and six states to record the possible outcomes of the first throw. So, with an obvious encoding, our state space is $$S=\{\varepsilon,1,2,\ldots,6,11,12,\ldots,66\},$$ with $1+6+36=43$ states in total.\par
            States $13,\, 22$ and $31$ are absorbing states (we stop when consecutive throws add to $4$), so we add a single looping transition (with assigned probability $1$) to each of them. Then, for the non-absorbing states, we add transitions with probability $\frac{1}{6}$ as follows: $(i)\, \varepsilon \to i$, for $i\in \{1,\ldots,6\},\, (ii)\, i\to ij$ for all $i,\,j\in \{1,\ldots,6\}$ and $(iii)\, ij\to jk$ for all $i,\, j,\, k \in \{1,\ldots,6\}$. So, for example, if we have already thrown a $4$ and a $2$, then with probability $\frac{1}{6}$ we throw a $5$ and make the transition $42\to 25$. Using first-step analysis we could in principle compute the expected time to absorption, which is the expected time to observing consecutive throws summing to $4$. However, we can simplify the calculation dramatically by working with a simpler Markov chain.
            \item We can get away with just three states, $\{0, 1, 2\}$. The interpretation of state $0$ is: “either we have not thrown the die yet (i.e., $t = 0$), or the previous throw was $4$, $5$ or $6$”. The interpretation of state $1$ is “the previous throw was $1$, $2$ or $3$, but we haven’t yet observed consecutive throws summing to $4$”. The interpretation of state $2$ is “we have observed consecutive throws summing to $4$”. The transition matrix is then 
            $$P=\begin{pmatrix}
                \frac{1}{2} & \frac{1}{2} & 0\\
                \frac{1}{2} & \frac{1}{3} & \frac{1}{6}\\
                0 & 0 & 1
            \end{pmatrix}$$
            Each of the entries may be checked for correctness. Suppose, for example, that the current state is 1. The previous roll was $1$, $2$ or $3$. With probability $\frac{1}{2}$ we will roll $4$, $5$ or $6$ and return to state $0$. With probability $\frac{1}{6}$ we will roll the number that complements the previous roll by summing to $4$, and hence move to state $2$. With the remaining probability $1-\frac{1}{2}-\frac{1}{6}=\frac{1}{3}$, we remain in state $1$.
            \item If we set $X_0 = 0$ then the number of rolls the process lasts is equal to the time of absorption (in the sole absorbing state, $2$). Define $T = min{t : X_t = 2}$ to be the time to absorption, and $u_i = \mathbb{E}(T\, | \, X_0 = i)$ for $i = 0, 1, 2$. Then
            \begin{align*}
                u_0 &= 1+\frac{1}{2}u_0+\frac{1}{2}\\
                u_1 &= 1+\frac{1}{2}u_0+\frac{1}{3}u_1+\frac{1}{6}u_2\\
                u_2 &= 0.
            \end{align*}
            Simplifing:
            \begin{align*}
                u_0 &= u_1+2\\
                4u_1 &= 6+3u_0.
            \end{align*}
            Solving these equations gives $u_1 = 12$, and $\mathbb{E}(T) = u_0 = 14$.            
        \end{enumerate}
        \item 
        \begin{enumerate}
            \item State $4$. (States $4$ and $5$ are absorbing because $p_{44} = p_{55} = 1$.)
            \item Let $T$ be the time of absorption and define $a_i = \mathbb{P}(X_T = 5\, |\, X_0 = i)$. By first-step analysis we have
            \begin{align*}
                a_1 &= \frac{2}{3}a_2+\frac{1}{3}a_3\\
                a_2 &= \frac{1}{2}a_2+\frac{1}{2}a_3+\frac{1}{6}\\
                a_3 &= \frac{1}{2}a_2+\frac{1}{4}.
            \end{align*}
            These are easily solved to give $\mathbb{P}(X_T = 5\, |\, X_0 = 1) = a_1 = \frac{2}{3}$ (and $a_2 = \frac{7}{10} \, \text{and}\, a_3 = \frac{3}{5}$).
            \item Let $u_i = \mathbb{E}(T | X_0 = i)$. By first step analysis we have
        \begin{align*}
            u_1 &= 1 + \frac{2}{3}u_2 + \frac{1}{3}u_3\\
            u_2 &= 1 + \frac{1}{3}u_2 + \frac{1}{2}u_3\\
            u_3 &= 1 + \frac{1}{2}u_2.
        \end{align*}
        These are easily solved to give $\mathbb{E}(T) = u_1 = \frac{13}{3}$ (and $u_2 = \frac{18}{5} \, \text{and}\, u_3 = \frac{14}{5}$).
        \item Let $V = |\{n : 0 \leq n \leq T − 1, X_n = 2\}|$. Let $v_i = \mathbb{E}(V | X_0 = i)$ be the expected number of visits to state $2$ before absorption starting from state $i$. By first step analysis we have
        \begin{align*}
            v_1 &= \frac{2}{3}v_2 + \frac{1}{3}v_3\\
            v_2 &= 1 + \frac{1}{3}v_2 + \frac{1}{2}v_3\\
            v_3 &= \frac{1}{2}v_2.
        \end{align*}
        These are easily solved to give $\mathbb{E}(V ) = v_1 = 2$ (and $v_2 = \frac{12}{5}\,\text{and}\, v_3 = \frac{6}{5}$).
        \item Let $w(1) = 0$, $w(2) = 10$ and $w(3) = −5$. Your gain is $$G = \sum_{i=0}^{T-1}w(X_i).$$ Let $g_i = \mathbb{E}(G\, |\, X_0 = i)$ be your expected gain up to absorption starting from state $i$. By first step analysis
        \begin{align*}
            g_1 &= \frac{2}{3}g_2+\frac{1}{3}g_3\\
            g_2 &= 10+\frac{1}{3}g_2+\frac{1}{2}g_3\\
            g_3 &= -5+\frac{1}{2}g_2.
        \end{align*}
        These are easily solved to give $\mathbb{E}(G) = g_1 = \frac{40}{3}$ (and $g_2 = 18$ and $g_3 = 4$).\par
        Alternatively: noticing that the process spends exactly $T − 1$ steps in states $2$ and $3$ and that $V$ of them are in state $2$ we have that $$G = 10V-5(T-1-V).$$ By linearity of expectation $$\mathbb{E}(G) = 10\mathbb{E}(V ) − 5\mathbb{E}(T) + 5 + 5\mathbb{E}(V) = 15 \mathbb{E}(V) − 5\mathbb{E}(T) + 5.$$ Putting in the numbers calculated in parts (c) and (d) we get $\mathbb{E}(G) = 15 \times 2 − 5 \times \frac{13}{3} + 5 = \frac{40}{3}$, as before.
        \end{enumerate}
        \item The simplest example is probably to take two absorbing states and a pair of states which are not absorbing which the chain can never leave. For instance take $S =\{1, 2, 3, 4, 5\}$, $X_0 = 0$ and transition matrix
        $$P = \begin{pmatrix}
            0 & 1/3 & 1/3 & 1/3 & 0\\
            0 & 1 & 0 & 0 & 0\\
            0 & 0 & 1 & 0 & 0\\
            0 & 0 & 0 & 1/2 & 1/2\\
            0 & 0 & 0 & 1/2 & 1/2
        \end{pmatrix}$$
        (Draw the transition graph to see what is going on).\par
        Suppose we wish to know the probability of eventual absorption in state $2$. Letting $T$ be the time to absorption, the first step analysis equations for $a_i = \mathbb{E}(X_T = 2\, |\, X_0 = i)$ are $a_2 = 1,\, a_3 = 0$ and
        \begin{align*}
            a_1 &= \frac{1}{3} + \frac{1}{3}a_4\\
            a_4 &= \frac{1}{2}a_4 + \frac{1}{2}a_5\\
            a_5 &= \frac{1}{2}a_4 + \frac{1}{2}a_5
        \end{align*}
        These do not have a unique solution; we could set $a_4 = a_5$ to be anything. In this example, $T$ is not finite with probability $1$, so we shouldn’t really talk about the event “$X_T = 2$”. But if we define ai to be the probability of eventual absorption in state $2$, we can still make sense of the variables and the equations. Since it is impossible to get from state $4$ or state $5$ to state $2$ we know that $a_4 = a_5 = 0$; with this additional information we get $a_1 = \frac{1}{3}$. You will get similar behaviour to this whatever example you decided upon.        
    \end{enumerate}
\end{document}