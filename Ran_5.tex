\documentclass[11pt,a4paper]{report}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts,amsmath,amssymb,suetterl}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[utf8]{inputenc}

\usepackage{fontawesome}
\DeclareUnicodeCharacter{2212}{-}
\usepackage{mathrsfs}

\usepackage[nodisplayskipstretch]{setspace}
\usepackage{hyperref}


\setstretch{1.5}


\fancyfoot[C]{\thepage}

\renewcommand{\footrulewidth}{0pt}
\parindent 0ex
\setlength{\parskip}{1em}

\newenvironment{psmallmatrix}
  {\left(\begin{smallmatrix}}
  {\end{smallmatrix}\right)}

\begin{document}
    \textbf{MTH6141 Random Processes, 2018, Exercise Sheet 4.}\par
    Please drop your answers to in the Random Processes coursework box by 5pm on Thursday 8th February. You are encouraged to hand in as many questions as you can, and a minimum of Q1 and Q5.\\
    Please send comments and corrections to \href{d.ellis@qmul.ac.uk}{d.ellis@qmul.ac.uk}.
    \begin{enumerate}
        \item For each of the following transition matrices, say whether the corresponding Markov chain is irreducible, regular, or neither. Which of them have a unique equilibrium distribution, and what is it? Which of them have a limiting distribution Justify your answers.
        \begin{enumerate}
            \item
            $$
            \begin{pmatrix}
                \frac{1}{2} & \frac{1}{2} & 0 & 0\\
                0 & \frac{1}{3} & \frac{2}{3} & 0\\
                0 & 0 & \frac{1}{2} & \frac{1}{2}\\
                \frac{1}{3} & 0 & 0 & \frac{2}{3}
            \end{pmatrix}
            $$
            %
            \item
            $$
            \begin{pmatrix}
                \frac{2}{5} & \frac{1}{5} & \frac{2}{5}\\
                0 & 1 & 0\\
                0 & 0 & 1
            \end{pmatrix}
            $$
            %
            \item
            $$
            \begin{pmatrix}
                \frac{1}{2} & \frac{1}{2} & 0\\
                0 & \frac{1}{2} & \frac{1}{2}\\
                0 & 0 & 1
            \end{pmatrix}
            $$
            %
            \item
            $$
            \begin{pmatrix}
                \frac{1}{2} & \frac{1}{} & \frac{1}{4}\\
                0 & 0 & 1\\
                0 & 1 & 0
            \end{pmatrix}
            $$
            %
            \item
            $$
            \begin{pmatrix}
                0 & \frac{1}{2} & 0 & \frac{1}{2}\\
                0 & 0 & 1 & 0\\
                0 & \frac{1}{2} & 0 & \frac{1}{2}\\
                1 & 0 & 0 & 0\\
            \end{pmatrix}
            $$
        \end{enumerate}
        %
        \item 
        \begin{enumerate}
            \item Prove that if an irreducible Markov chain on a finite state space has a state $i$ with $p_{ii} > 0$, then it is regular.
            \item  Does the same result hold if we allow the state space to be infinite? Justify your answer.
        \end{enumerate}
        %
        \item Let $(X_0, X_1, X_2, \ldots)$ be the Markov chain with state space $\{1, 2, 3,4\}$ and transition matrix
        $$
        \begin{pmatrix}
            0 & \frac{1}{2} & p & \frac{1}{2}-p\\
            0 & 0 & 0 & 1\\
            0 & 0 & 0 & 1\\
            1 & 0 & 0 & 0
        \end{pmatrix}
        $$
        for some $0 \leq p \leq 1/2$.
        \begin{enumerate}
            \item For which values of $p$ is this Markov chain irreducible? Justify your answer.
            \item For which values of p is this Markov chain regular? Justify your answer.
            \item For the range of values of $p$ covered by (b), calculate the limiting distribution of the Markov chain (as a function of $p$).
            \item Let $p$ be such that the Markov chain is irreducible but not regular. What is $\mathbb{P}(X_{1000} = 1\, | \, X_0 = 1)$ and why?
        \end{enumerate}
        \item  Show that if a Markov chain with a finite state space $S$ has a $symmetric$ transition matrix (meaning that $p_{i,j} = p_{j,i}$ for all $i, j$), then the uniform distribution on $S$ (meaning, the distribution with probability vector $w = (1/|S|, 1/|S|, \ldots , 1/|S|))$ is an equilibrium distribution for the Markov chain.
        \item  There are five light bulbs in a room, and no other sources of light. Each light bulb can either be on or off. Every minute, one of the five light bulbs is chosen at random (each is chosen with probability $1/5$), and its switch is flipped (if it was on, it is turned off, and if it was off, it is turned on).
        \begin{enumerate}
            \item Show how to model the level of light in the room (after t minutes) as a Markov chain with six states.
            \item Show that this Markov chain does not have a limiting distribution.
            \item Does this Markov chain have an equilibrium distribution? If so, find an equilibrium distribution, and say whether or not it is the only equilibrium distribution.
        \end{enumerate}
        
    \end{enumerate}
\end{document}